{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[sultan]: md5 -q ./emnist-digits.mat;\u001b[0m\n",
      "\u001b[01;31m[sultan]: Unable to run 'md5 -q ./emnist-digits.mat;'\u001b[0m\n",
      "\u001b[01;31m[sultan]: --{ TRACEBACK }----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[01;31m[sultan]: | NoneType: None\u001b[0m\n",
      "\u001b[01;31m[sultan]: | \u001b[0m\n",
      "\u001b[01;31m[sultan]: -------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[01;31m[sultan]: --{ STDERR }-------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[01;31m[sultan]: | /bin/sh: 1: md5: not found\u001b[0m\n",
      "\u001b[01;31m[sultan]: -------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[33m[sultan]: The following are additional information that can be used to debug this exception.\u001b[0m\n",
      "\u001b[33m[sultan]: The following is the context used to run:\u001b[0m\n",
      "\u001b[33m[sultan]: \t - cwd: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - sudo: False\u001b[0m\n",
      "\u001b[33m[sultan]: \t - user: mariogmarq\u001b[0m\n",
      "\u001b[33m[sultan]: \t - hostname: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - env: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - logging: True\u001b[0m\n",
      "\u001b[33m[sultan]: \t - executable: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - ssh_config: \u001b[0m\n",
      "\u001b[33m[sultan]: \t - src: None\u001b[0m\n",
      "\u001b[01;31m[sultan]: Unable to run 'md5 -q ./emnist-digits.mat;'\u001b[0m\n",
      "\u001b[01;31m[sultan]: --{ TRACEBACK }----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[01;31m[sultan]: | Traceback (most recent call last):\u001b[0m\n",
      "\u001b[01;31m[sultan]: |   File \"/home/mariogmarq/miniconda3/lib/python3.10/site-packages/sultan/api.py\", line 212, in run\u001b[0m\n",
      "\u001b[01;31m[sultan]: |     result = Result(process, commands, self._context, streaming, halt_on_nonzero=halt_on_nonzero)\u001b[0m\n",
      "\u001b[01;31m[sultan]: |   File \"/home/mariogmarq/miniconda3/lib/python3.10/site-packages/sultan/result.py\", line 59, in __init__\u001b[0m\n",
      "\u001b[01;31m[sultan]: |     self.dump_exception()\u001b[0m\n",
      "\u001b[01;31m[sultan]: |   File \"/home/mariogmarq/miniconda3/lib/python3.10/site-packages/sultan/result.py\", line 114, in dump_exception\u001b[0m\n",
      "\u001b[01;31m[sultan]: |     raise self._exception\u001b[0m\n",
      "\u001b[01;31m[sultan]: |   File \"/home/mariogmarq/miniconda3/lib/python3.10/site-packages/sultan/result.py\", line 95, in dump_exception\u001b[0m\n",
      "\u001b[01;31m[sultan]: |     raise subprocess.CalledProcessError(self.rc, ''.join(self._commands), self.stderr)\u001b[0m\n",
      "\u001b[01;31m[sultan]: | subprocess.CalledProcessError: Command 'md5 -q ./emnist-digits.mat;' returned non-zero exit status 127.\u001b[0m\n",
      "\u001b[01;31m[sultan]: | \u001b[0m\n",
      "\u001b[01;31m[sultan]: -------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[33m[sultan]: The following are additional information that can be used to debug this exception.\u001b[0m\n",
      "\u001b[33m[sultan]: The following is the context used to run:\u001b[0m\n",
      "\u001b[33m[sultan]: \t - cwd: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - sudo: False\u001b[0m\n",
      "\u001b[33m[sultan]: \t - user: mariogmarq\u001b[0m\n",
      "\u001b[33m[sultan]: \t - hostname: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - env: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - logging: True\u001b[0m\n",
      "\u001b[33m[sultan]: \t - executable: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - ssh_config: \u001b[0m\n",
      "\u001b[33m[sultan]: \t - src: None\u001b[0m\n",
      "\u001b[36m[sultan]: md5sum ./emnist-digits.mat | cut -f 1 -d \" \";\u001b[0m\n",
      "\u001b[36m[sultan]: md5 -q ./emnist-digits.mat;\u001b[0m\n",
      "\u001b[01;31m[sultan]: Unable to run 'md5 -q ./emnist-digits.mat;'\u001b[0m\n",
      "\u001b[01;31m[sultan]: --{ TRACEBACK }----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[01;31m[sultan]: | NoneType: None\u001b[0m\n",
      "\u001b[01;31m[sultan]: | \u001b[0m\n",
      "\u001b[01;31m[sultan]: -------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[01;31m[sultan]: --{ STDERR }-------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[01;31m[sultan]: | /bin/sh: 1: md5: not found\u001b[0m\n",
      "\u001b[01;31m[sultan]: -------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[33m[sultan]: The following are additional information that can be used to debug this exception.\u001b[0m\n",
      "\u001b[33m[sultan]: The following is the context used to run:\u001b[0m\n",
      "\u001b[33m[sultan]: \t - cwd: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - sudo: False\u001b[0m\n",
      "\u001b[33m[sultan]: \t - user: mariogmarq\u001b[0m\n",
      "\u001b[33m[sultan]: \t - hostname: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - env: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - logging: True\u001b[0m\n",
      "\u001b[33m[sultan]: \t - executable: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - ssh_config: \u001b[0m\n",
      "\u001b[33m[sultan]: \t - src: None\u001b[0m\n",
      "\u001b[01;31m[sultan]: Unable to run 'md5 -q ./emnist-digits.mat;'\u001b[0m\n",
      "\u001b[01;31m[sultan]: --{ TRACEBACK }----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[01;31m[sultan]: | Traceback (most recent call last):\u001b[0m\n",
      "\u001b[01;31m[sultan]: |   File \"/home/mariogmarq/miniconda3/lib/python3.10/site-packages/sultan/api.py\", line 212, in run\u001b[0m\n",
      "\u001b[01;31m[sultan]: |     result = Result(process, commands, self._context, streaming, halt_on_nonzero=halt_on_nonzero)\u001b[0m\n",
      "\u001b[01;31m[sultan]: |   File \"/home/mariogmarq/miniconda3/lib/python3.10/site-packages/sultan/result.py\", line 59, in __init__\u001b[0m\n",
      "\u001b[01;31m[sultan]: |     self.dump_exception()\u001b[0m\n",
      "\u001b[01;31m[sultan]: |   File \"/home/mariogmarq/miniconda3/lib/python3.10/site-packages/sultan/result.py\", line 114, in dump_exception\u001b[0m\n",
      "\u001b[01;31m[sultan]: |     raise self._exception\u001b[0m\n",
      "\u001b[01;31m[sultan]: |   File \"/home/mariogmarq/miniconda3/lib/python3.10/site-packages/sultan/result.py\", line 95, in dump_exception\u001b[0m\n",
      "\u001b[01;31m[sultan]: |     raise subprocess.CalledProcessError(self.rc, ''.join(self._commands), self.stderr)\u001b[0m\n",
      "\u001b[01;31m[sultan]: | subprocess.CalledProcessError: Command 'md5 -q ./emnist-digits.mat;' returned non-zero exit status 127.\u001b[0m\n",
      "\u001b[01;31m[sultan]: | \u001b[0m\n",
      "\u001b[01;31m[sultan]: -------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[33m[sultan]: The following are additional information that can be used to debug this exception.\u001b[0m\n",
      "\u001b[33m[sultan]: The following is the context used to run:\u001b[0m\n",
      "\u001b[33m[sultan]: \t - cwd: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - sudo: False\u001b[0m\n",
      "\u001b[33m[sultan]: \t - user: mariogmarq\u001b[0m\n",
      "\u001b[33m[sultan]: \t - hostname: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - env: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - logging: True\u001b[0m\n",
      "\u001b[33m[sultan]: \t - executable: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - ssh_config: \u001b[0m\n",
      "\u001b[33m[sultan]: \t - src: None\u001b[0m\n",
      "\u001b[36m[sultan]: md5sum ./emnist-digits.mat | cut -f 1 -d \" \";\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from flex.datasets import load\n",
    "from torchvision import transforms\n",
    "\n",
    "flex_dataset, test_data = load(\"federated_emnist\", return_test=True, split=\"digits\")\n",
    "\n",
    "mnist_transforms = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the pool 3589: 10 miners plus 3579 clients. The server is also an aggregator\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from flex.pool import init_server_model\n",
    "from flex.model import FlexModel\n",
    "\n",
    "from flexBlock.pool import PoFLBlockchainPool\n",
    "\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "@init_server_model\n",
    "def build_server_model():\n",
    "    server_flex_model = FlexModel()\n",
    "\n",
    "    server_flex_model[\"model\"] = SimpleNet()\n",
    "    # Required to store this for later stages of the FL training process\n",
    "    server_flex_model[\"criterion\"] = torch.nn.CrossEntropyLoss()\n",
    "    server_flex_model[\"optimizer_func\"] = torch.optim.Adam\n",
    "    server_flex_model[\"optimizer_kwargs\"] = {}\n",
    "    return server_flex_model\n",
    "\n",
    "pool = PoFLBlockchainPool(fed_dataset=flex_dataset, init_func=build_server_model, number_of_miners=10)\n",
    "\n",
    "clients = pool.clients\n",
    "servers = pool.servers\n",
    "aggregators = pool.aggregators\n",
    "\n",
    "print(\n",
    "    f\"Number of nodes in the pool {len(pool)}: {len(servers)} miners plus {len(clients)} clients. The server is also an aggregator\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "from flexBlock.pool import deploy_miner_model\n",
    "\n",
    "@deploy_miner_model\n",
    "def copy_server_model_to_clients(server_flex_model: FlexModel):\n",
    "    return copy.deepcopy(server_flex_model)\n",
    "\n",
    "\n",
    "servers.map(copy_server_model_to_clients, clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def train(client_flex_model: FlexModel, client_data: Dataset):\n",
    "    train_dataset = client_data.to_torchvision_dataset(transform=mnist_transforms)\n",
    "    client_dataloader = DataLoader(train_dataset, batch_size=20)\n",
    "    model = client_flex_model[\"model\"]\n",
    "    optimizer = client_flex_model[\"optimizer_func\"](\n",
    "        model.parameters(), **client_flex_model[\"optimizer_kwargs\"]\n",
    "    )\n",
    "    model = model.train()\n",
    "    model = model.to(device)\n",
    "    criterion = client_flex_model[\"criterion\"]\n",
    "    for _ in range(1):\n",
    "        for imgs, labels in client_dataloader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(imgs)\n",
    "            loss = criterion(pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexBlock.pool import send_weights_to_miner\n",
    "\n",
    "@send_weights_to_miner\n",
    "def get_clients_weights(client_flex_model: FlexModel):\n",
    "    weight_dict = client_flex_model[\"model\"].state_dict()\n",
    "    return [weight_dict[name] for name in weight_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import set_aggregated_weights\n",
    "\n",
    "\n",
    "@set_aggregated_weights\n",
    "def set_agreggated_weights_to_server(server_flex_model: FlexModel, aggregated_weights):\n",
    "    with torch.no_grad():\n",
    "        weight_dict = server_flex_model[\"model\"].state_dict()\n",
    "        for layer_key, new in zip(weight_dict, aggregated_weights):\n",
    "            weight_dict[layer_key].copy_(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_global_model(server_flex_model: FlexModel, test_data: Dataset):\n",
    "    model = server_flex_model[\"model\"]\n",
    "    model.eval()\n",
    "    test_acc = 0\n",
    "    total_count = 0\n",
    "    model = model.to(device)\n",
    "    # get test data as a torchvision object\n",
    "    test_dataset = test_data.to_torchvision_dataset(transform=mnist_transforms)\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset, batch_size=256, shuffle=True, pin_memory=False\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_dataloader:\n",
    "            total_count += target.size(0)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            test_acc += pred.eq(target.data.view_as(pred)).long().cpu().sum().item()\n",
    "\n",
    "    test_acc /= total_count\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import fed_avg\n",
    "\n",
    "def train_n_rounds(n_rounds):\n",
    "    for i in range(n_rounds):\n",
    "        print(f\"\\nRunning round: {i+1} of {n_rounds}\")\n",
    "        # Deploy the server model to the selected clients\n",
    "        pool.servers.map(copy_server_model_to_clients, clients)\n",
    "        # Each selected client trains her model\n",
    "        clients.map(train)\n",
    "        # The aggregador collects weights from the selected clients and aggregates them\n",
    "        pool.aggregators.map(get_clients_weights, clients)\n",
    "        pool.aggregate(fed_avg)\n",
    "        # The aggregator send its aggregated weights to the server\n",
    "        pool.aggregators.map(set_agreggated_weights_to_server, pool.servers)\n",
    "        metrics = pool.servers.map(evaluate_global_model)\n",
    "        acc = metrics[0]\n",
    "        print(f\"Server: Test acc: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running round: 1 of 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_n_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m, in \u001b[0;36mtrain_n_rounds\u001b[0;34m(n_rounds)\u001b[0m\n\u001b[1;32m      7\u001b[0m pool\u001b[38;5;241m.\u001b[39mservers\u001b[38;5;241m.\u001b[39mmap(copy_server_model_to_clients, clients)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Each selected client trains her model\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mclients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# The aggregador collects weights from the selected clients and aggregates them\u001b[39;00m\n\u001b[1;32m     11\u001b[0m pool\u001b[38;5;241m.\u001b[39maggregators\u001b[38;5;241m.\u001b[39mmap(get_clients_weights, clients)\n",
      "File \u001b[0;32m~/Documentos/tfg/FLEXible/flex/pool/pool.py:116\u001b[0m, in \u001b[0;36mFlexPool.map\u001b[0;34m(self, func, dst_pool, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Method used to send messages from one pool to another. The pool using\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03mthis method is the source pool, and it will send a message, apply a function,\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03mto the destination pool. If no destination pool is provided, then the function is applied\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    length of the returned values equals the number of actors in the source pool.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dst_pool \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 116\u001b[0m     res \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    117\u001b[0m         func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_models\u001b[38;5;241m.\u001b[39mget(i), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mget(i), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actors\n\u001b[1;32m    119\u001b[0m     ]\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m FlexPool\u001b[38;5;241m.\u001b[39mcheck_compatibility(\u001b[38;5;28mself\u001b[39m, dst_pool):\n\u001b[1;32m    121\u001b[0m     res \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    122\u001b[0m         func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_models\u001b[38;5;241m.\u001b[39mget(i), dst_pool\u001b[38;5;241m.\u001b[39m_models, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actors\n\u001b[1;32m    124\u001b[0m     ]\n",
      "File \u001b[0;32m~/Documentos/tfg/FLEXible/flex/pool/pool.py:117\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Method used to send messages from one pool to another. The pool using\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03mthis method is the source pool, and it will send a message, apply a function,\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03mto the destination pool. If no destination pool is provided, then the function is applied\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    length of the returned values equals the number of actors in the source pool.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dst_pool \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     res \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 117\u001b[0m         \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actors\n\u001b[1;32m    119\u001b[0m     ]\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m FlexPool\u001b[38;5;241m.\u001b[39mcheck_compatibility(\u001b[38;5;28mself\u001b[39m, dst_pool):\n\u001b[1;32m    121\u001b[0m     res \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    122\u001b[0m         func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_models\u001b[38;5;241m.\u001b[39mget(i), dst_pool\u001b[38;5;241m.\u001b[39m_models, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actors\n\u001b[1;32m    124\u001b[0m     ]\n",
      "Cell \u001b[0;32mIn[17], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(client_flex_model, client_data)\u001b[0m\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(pred, labels)\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 22\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/optim/adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    152\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    155\u001b[0m         group,\n\u001b[1;32m    156\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m         state_steps)\n\u001b[0;32m--> 163\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/optim/adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 311\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/optim/adam.py:434\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m--> 434\u001b[0m     \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(params[i]):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_n_rounds(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
