{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cifar-10 Example\n",
    "In this notebook we are going to train a basic convolutional neural network in a federated blockchain environment. This example supose previous experience with pytorch and the flex framework for federated learning experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to download the dataset and create the according `FedDataset` for this experiment. We are not loading a test dataset since we are not going to have a server per-se."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import Dataset, FedDatasetConfig, FedDataDistribution\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "cifar_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_data = datasets.CIFAR10(\n",
    "    root=\".\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=None,  # Note that we do not specify transforms here, we provide them later in the training process\n",
    ")\n",
    "\n",
    "config = FedDatasetConfig(seed=0)\n",
    "config.replacement = False\n",
    "config.n_nodes = 100\n",
    "\n",
    "flex_dataset = FedDataDistribution.from_config(\n",
    "    centralized_data=Dataset.from_torchvision_dataset(train_data), config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to create our pool as usual. Note that this time we are using a `PoSBlockchainPool`, that is a pool that uses a Proof of Stake blockchain to coordinate the training process. In this pool every client is also an aggregator. We are opting for a PoS blockchain due to the fact of low computational power neccesary to run the blockchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from flexBlock.pool import PoSBlockchainPool\n",
    "from flex.pool import init_server_model\n",
    "from flex.model import FlexModel\n",
    "\n",
    "\n",
    "\n",
    "def get_model(num_classes=10):\n",
    "    # Model for cifar-10 32x32x3\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(3, 6, 3),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "        nn.Conv2d(6, 16, 3),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(46656, 120),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(120, 84),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(84, num_classes)\n",
    "    )\n",
    "\n",
    "\n",
    "@init_server_model\n",
    "def build_server_model():\n",
    "    server_flex_model = FlexModel()\n",
    "    server_flex_model[\"model\"] = get_model().to(device)\n",
    "    # Required to store this for later stages of the FL training process\n",
    "    server_flex_model[\"criterion\"] = torch.nn.CrossEntropyLoss()\n",
    "    server_flex_model[\"optimizer_func\"] = torch.optim.Adam\n",
    "    server_flex_model[\"optimizer_kwargs\"] = {}\n",
    "\n",
    "    return server_flex_model\n",
    "\n",
    "flex_pool = PoSBlockchainPool(\n",
    "    fed_dataset=flex_dataset, init_func=build_server_model\n",
    ")\n",
    "\n",
    "clients = flex_pool.clients\n",
    "servers = flex_pool.servers\n",
    "aggregators = flex_pool.aggregators\n",
    "\n",
    "print(\n",
    "    f\"Number of nodes in the pool {len(flex_pool)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select a subset of clients in each round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select clients\n",
    "clients_per_round = 2\n",
    "selected_clients_pool = clients.select(clients_per_round)\n",
    "selected_clients = selected_clients_pool.clients\n",
    "\n",
    "print(f'Server node is indentified by key \"{servers.actor_ids[0]}\"')\n",
    "print(\n",
    "    f\"Selected {len(selected_clients.actor_ids)} client nodes of a total of {len(clients.actor_ids)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import deploy_server_model_pt\n",
    "\n",
    "servers.map(deploy_server_model_pt, selected_clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the train loop manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train(client_flex_model: FlexModel, client_data: Dataset):\n",
    "    train_dataset = client_data.to_torchvision_dataset(transform=cifar_transforms)\n",
    "    client_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "    model = client_flex_model[\"model\"]\n",
    "    model = model.to(device)\n",
    "    client_flex_model[\"previous_model\"] = deepcopy(\n",
    "        model\n",
    "    )  # Required to use `collect_client_diff_weights_pt` primitive\n",
    "    optimizer = client_flex_model[\"optimizer_func\"](\n",
    "        model.parameters(), **client_flex_model[\"optimizer_kwargs\"]\n",
    "    )\n",
    "    model = model.train()\n",
    "    criterion = client_flex_model[\"criterion\"]\n",
    "    epochs = 1\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        for imgs, labels in tqdm(client_dataloader):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(imgs)\n",
    "            loss = criterion(pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train our clients as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_clients.map(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important difference with a normal flex example is that the weight collection functions are not compatible with flex. In case that we want to use a flex built-in collection primitive or a custom one that we built for flex, we can adapt it to the blockchain environment using the function `collect_to_send_wrapper`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import collect_client_diff_weights_pt\n",
    "from flexBlock.pool.primitives import collect_to_send_wrapper\n",
    "\n",
    "# Make the collect_client_diff_weights_pt primitive blockchain ready\n",
    "collect_client_diff = collect_to_send_wrapper(collect_client_diff_weights_pt)\n",
    "\n",
    "aggregators.map(collect_client_diff, selected_clients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the weights need to be shared between miners. In a real life scenario this would be done through a gossip mechanishm between miners, we can archieve this by calling the `flex_pool.gossip` method. Then, we are ready to mine a block, this is done as part of the aggregate step. The `aggregate` method will run the consensus mechanism for our architecture (in our case, proof of stake) and the winner miner will run the given aggregation function. In this case, we are using a simple average.\n",
    "\n",
    "Finally, we can update the weights of the clients and repeat the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import fed_avg\n",
    "\n",
    "flex_pool.gossip()\n",
    "flex_pool.aggregate(fed_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the federated experiment for a few rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import set_aggregated_diff_weights_pt, deploy_server_model_pt\n",
    "\n",
    "# Auxiliar function to clear unused gpu mem in clients\n",
    "def clean_up_models(client_model: FlexModel, _):\n",
    "    import gc\n",
    "\n",
    "    client_model.clear()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "def train_n_rounds(n_rounds, clients_per_round=20):\n",
    "    pool = PoSBlockchainPool(\n",
    "        fed_dataset=flex_dataset, init_func=build_server_model\n",
    "    )\n",
    "    for i in range(n_rounds):\n",
    "        print(f\"\\nRunning round: {i+1} of {n_rounds}\")\n",
    "        selected_clients_pool = pool.clients.select(clients_per_round)\n",
    "        selected_clients = selected_clients_pool.clients\n",
    "        print(f\"Selected clients for this round: {len(selected_clients)}\")\n",
    "        # Deploy the server model to the selected clients\n",
    "        pool.servers.map(deploy_server_model_pt, selected_clients)\n",
    "        # Each selected client trains her model\n",
    "        selected_clients.map(train)\n",
    "        # The aggregador collects weights from the selected clients and aggregates them\n",
    "        pool.aggregators.map(collect_client_diff, selected_clients)\n",
    "        pool.gossip()\n",
    "        pool.aggregate(fed_avg)\n",
    "        # The aggregator send its aggregated weights to the server\n",
    "        pool.aggregators.map(set_aggregated_diff_weights_pt, pool.servers)\n",
    "        # Optional: clean-up unused memory\n",
    "        selected_clients.map(clean_up_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n_rounds(10, clients_per_round=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
